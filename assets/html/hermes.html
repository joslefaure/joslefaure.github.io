<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="description" content="Long-Form video understanding with Episodes and Semantics." />
    <meta name="keywords" content="Episode, Semantics, Video-Understanding, HERMES" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RM27MDSL17"></script>
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }

      gtag("js", new Date());

      gtag("config", "G-PYVRSFMDRL");
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

    <link rel="stylesheet" href="../static/css/bulma.min.css" />
    <link rel="stylesheet" href="../static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="../static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="../static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="../static/css/index.css" />
    <link rel="icon" href="../img/favicon_ai.jpeg" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="../static/js/fontawesome.all.min.js"></script>
    <script src="../static/js/bulma-carousel.min.js"></script>
    <script src="../static/js/bulma-slider.min.js"></script>
    <script src="../static/js/index.js"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://keunhong.com">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a
                class="navbar-item"
                href="https://openaccess.thecvf.com/content/WACV2023/html/Faure_Holistic_Interaction_Transformer_Network_for_Action_Detection_WACV_2023_paper.html"
              >
                HIT
              </a>
              <a class="navbar-item" href="https://arxiv.org/abs/2304.04688"> iCLIP </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics</h1>
              <h2 class="title is-3">ICCV 2025</h3>
              <div class="is-size-5 publication-authors">
                <span class="author-block"> <a href="https://joslefaure.github.io/">Gueter Josmy Faure</a><sup>1</sup>, </span>
                <span class="author-block"> <a href="https://www.cmlab.csie.ntu.edu.tw/~jiafongyeh/">Jia-Fong Yeh</a><sup>1</sup>, </span>
                <span class="author-block"> <a href="https://minhungchen.netlify.app/">Min-Hung Chen</a><sup>2</sup>, </span>
                <span class="author-block"> <a href="">Hung-Ting Su</a><sup>1</sup>, </span>
                <span class="author-block"> <a href="https://winstonhsu.info/">Winston H. Hsu</a><sup>1,3</sup>, </span>
                <span class="author-block"> <a href="">Shang-Hong Lai</a><sup>4</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>National Taiwan University, </span>
                <span class="author-block"><sup>2</sup>NVIDIA, </span>
                <span class="author-block"><sup>3</sup>Mobile Drive Technology, </span>
                <span class="author-block"><sup>4</sup>National Tsing Hua University</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2408.17443" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
                  <span class="link-block">
                    <a href="" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span>
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/joslefaure/HERMES" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Dataset Link. -->
                  <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="../static/images/hermes/hermes_banner.png" alt="Teaser image." />
          <h2 class="subtitle has-text-centered">
            <span class="dnerf">HERMES</span> simulates episodic memory accumulation to capture action sequences from long videos and reinforces them
            with semantic knowledge dispersed throughout the video.
          </h2>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Long-form video understanding presents unique challenges that extend beyond traditional short-video analysis approaches, particularly in capturing long-range dependencies, processing redundant information efficiently, and extracting high-level semantic concepts.
              </p>
              <p>
                To address these challenges, we propose a novel approach that more accurately reflects human cognition. This paper introduces HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics, featuring two versatile modules that can enhance existing video-language models or operate as a standalone system. Our Episodic COmpressor (ECO) efficiently aggregates representations from micro to semi-macro levels, reducing computational overhead while preserving temporal dependencies. Our Semantics ReTRiever (SeTR) enriches these representations with semantic information by focusing on broader context, dramatically reducing feature dimensionality while preserving relevant macro-level information. We demonstrate that these modules can be seamlessly integrated into existing SOTA models, consistently improving their performance while reducing inference latency by up to 43% and memory usage by 46%. As a standalone system, HERMES achieves state-of-the-art performance across multiple long-video understanding benchmarks in both zero-shot and fully-supervised settings.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Method Overview</h2>
              <img src="../static/images/hermes/hermes_method.png" alt="method image." />
          </div>
        </div>
        <!--/ Paper video. -->
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Results and Ablations</h2>
          </div>
        </div>
        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h3 class="title is-4">Long Procedural Video</h3>
            <div class="publication-video">
              <img src="../static/images/hermes/results_main.png" alt="main results image." />
            </div>
          </div>
        </div>
        <!--/ Paper video. -->
        <div class="columns is-centered">
          <!-- Visual Effects. -->
          <div class="column">
            <div class="content">
              <h3 class="title is-4">Long Movies (MovieChat)</h3>
              <img src="../static/images/hermes/results_moviechat.png" alt="result mvchat." />
            </div>
          </div>
          <!--/ Visual Effects. -->

          <!-- Matting. -->
          <div class="column">
            <h3 class="title is-4">Ablations: Accuracy vs Inference Time</h3>
            <div class="columns is-centered">
              <div class="content has-text-justified">
                <p>Faster and better than existing SOTA models.</p>
              </div>
              <div class="column content">
                <img src="../static/images/hermes/accuracy_vs_speed.png" alt="result coin." />
              </div>
            </div>
          </div>
        </div>
        <!--/ Matting. -->

        <!-- Animation. -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Plug-and-Play Results</h2>

            <!-- Interpolating. -->
            <!-- <h3 class="title is-4">Interpolating states</h3> -->
            <div class="content has-text-justified">
              <p>No tradeoffs, improvements across the board.</p>
            </div>
            <div class="publication-video">
              <img src="../static/images/hermes/plug_and_play.png" alt="result plug." />
            </div>
            <!--/ Interpolating. -->

            <!-- Re-rendering. -->
            <h2 class="title is-3">Qualitative Results</h2>
            <div class="content has-text-justified">
              <p>
                <span class="dnerf">HERMES</span> excels at fine-grained understanding of arbitrarily long videos. Furthermore, it has the rare
                quality of knowing when it doesn't know.
              </p>
            </div>
            <div class="content has-text-centered">
              <img src="../static/images/qualitative_1.png" alt="qualitative 1" />
            </div>
            <!--/ Re-rendering. -->

            <!-- Re-rendering. -->
            <div class="content has-text-justified">
              <p>
                <span class="dnerf">HERMES</span> can identify animal species, accurately count them. It can also determine peoples' relationships by
                watching them interact across thousands of frames.
              </p>
            </div>
            <div class="content has-text-centered">
              <img src="../static/images/qualitative_ext.png" alt="qualitative 1" />
            </div>
            <!--/ Re-rendering. -->
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@misc{faure2024hermestemporalcoherentlongformunderstanding,
          title={HERMES: temporal-coHERent long-forM understanding with Episodes and Semantics}, 
          author={Gueter Josmy Faure and Jia-Fong Yeh and Min-Hung Chen and Hung-Ting Su and Shang-Hong Lai and Winston H. Hsu},
          year={2024},
          eprint={2408.17443},
          archivePrefix={arXiv},
          primaryClass={cs.CV},
          url={https://arxiv.org/abs/2408.17443}, 
    }</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <a class="icon-link" href="https://arxiv.org/abs/2408.17443">
            <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="https://github.com/joslefaure/HERMES" class="external-link" disabled>
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and licenced under a
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
