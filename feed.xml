<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://joslefaure.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://joslefaure.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-26T07:33:42+00:00</updated><id>https://joslefaure.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Let’s demystify overfitting</title><link href="https://joslefaure.github.io/blog/2024/lets-demystify-overfitting/" rel="alternate" type="text/html" title="Let’s demystify overfitting"/><published>2024-07-19T07:41:02+00:00</published><updated>2024-07-19T07:41:02+00:00</updated><id>https://joslefaure.github.io/blog/2024/lets-demystify-overfitting</id><content type="html" xml:base="https://joslefaure.github.io/blog/2024/lets-demystify-overfitting/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Semantic and Episodic Network for Long-Form Video Understanding</title><link href="https://joslefaure.github.io/blog/2024/SCENE/" rel="alternate" type="text/html" title="Semantic and Episodic Network for Long-Form Video Understanding"/><published>2024-07-15T10:06:00+00:00</published><updated>2024-07-15T10:06:00+00:00</updated><id>https://joslefaure.github.io/blog/2024/SCENE</id><content type="html" xml:base="https://joslefaure.github.io/blog/2024/SCENE/"><![CDATA[<h3 id="paper--code"><a href="https://github.com/joslefaure/SCENE">Paper</a> / <a href="https://github.com/joslefaure/SCENE">Code</a></h3> <h2 id="abstract">Abstract</h2> <p>While existing research often treats long-form videos as extended short videos, we propose a novel approach that more accurately reflects human cognition. This paper introduces <strong>SCENE</strong>: <strong>S</strong>emanti<strong>C</strong> and <strong>E</strong>pisodic <strong>NE</strong>twork for Long-Form Video Understanding, a model that simulates episodic memory accumulation to capture action sequences and reinforces them with semantic knowledge dispersed throughout the video. Our work makes two key contributions: First, we develop an Episodic Memory ComprEssor (EMCEE) module that efficiently aggregates crucial representations from micro to semi-macro levels. Second, we propose a Semantic Knowledge ExtrAcTor (SKEAT) that enhances these aggregated representations with semantic information by focusing on the broader context, dramatically reducing feature dimensionality while preserving relevant macro-level information. Extensive experiments demonstrate that <strong>SCENE</strong> achieves state-of-the-art performance across multiple long-video understanding benchmarks in both zero-shot and fully-supervised settings. Our code will be made public at <a href="https://github.com/joslefaure/SCENE">SCENE</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/intuition-480.webp 480w,/assets/img/intuition-800.webp 800w,/assets/img/intuition-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/intuition.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="main-contributions">Main Contributions</h2> <p>Our key contributions are as follows:</p> <ul> <li>We propose an Episodic Memory ComprEssor (EMCEE) to stream through the video and keep important episodes by aggregating similar scenes. EMCEE enables efficient processing of extended video sequences while preserving temporal coherence and narrative structure.</li> <li>We develop a Semantic Knowledge Extractor (SKEAT) that enhances the model’s understanding of long videos by distilling high-level semantic cues, providing a cohesive framework for understanding the context and themes within long-form videos.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/method-480.webp 480w,/assets/img/method-800.webp 800w,/assets/img/method-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/method.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="results-and-ablations">Results and Ablations</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/results-480.webp 480w,/assets/img/results-800.webp 800w,/assets/img/results-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="qualitative-results">Qualitative Results</h2> <h2 id="citation">Citation</h2>]]></content><author><name>First Author Name</name></author><category term="paper"/><category term="video-understanding"/><category term="llm"/><category term="paper"/><summary type="html"><![CDATA[A novel method that simulates episodic memory accumulation to capture action sequences and reinforces them with semantic knowledge dispersed throughout the video.]]></summary></entry><entry><title type="html">A gentle introduction to the Kalman Filter</title><link href="https://joslefaure.github.io/blog/2023/a-gentle-introduction-to-the-kalman-filter/" rel="alternate" type="text/html" title="A gentle introduction to the Kalman Filter"/><published>2023-02-01T10:21:16+00:00</published><updated>2023-02-01T10:21:16+00:00</updated><id>https://joslefaure.github.io/blog/2023/a-gentle-introduction-to-the-kalman-filter</id><content type="html" xml:base="https://joslefaure.github.io/blog/2023/a-gentle-introduction-to-the-kalman-filter/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Euclidean Distance and Cosine Similarity. Which One to Use and When?</title><link href="https://joslefaure.github.io/blog/2020/euclidean-distance-and-cosine-similarity-which-one-to-use-and-when/" rel="alternate" type="text/html" title="Euclidean Distance and Cosine Similarity. Which One to Use and When?"/><published>2020-09-03T05:53:10+00:00</published><updated>2020-09-03T05:53:10+00:00</updated><id>https://joslefaure.github.io/blog/2020/euclidean-distance-and-cosine-similarity-which-one-to-use-and-when</id><content type="html" xml:base="https://joslefaure.github.io/blog/2020/euclidean-distance-and-cosine-similarity-which-one-to-use-and-when/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Society and the “Modern man”</title><link href="https://joslefaure.github.io/blog/2019/society-and-the-modern-man/" rel="alternate" type="text/html" title="Society and the “Modern man”"/><published>2019-03-19T03:12:37+00:00</published><updated>2019-03-19T03:12:37+00:00</updated><id>https://joslefaure.github.io/blog/2019/society-and-the-modern-man</id><content type="html" xml:base="https://joslefaure.github.io/blog/2019/society-and-the-modern-man/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">We are all screwed, yet no one cares (part II)</title><link href="https://joslefaure.github.io/blog/2019/we-are-all-screwed-yet-no-one-cares-part-ii/" rel="alternate" type="text/html" title="We are all screwed, yet no one cares (part II)"/><published>2019-03-15T06:34:28+00:00</published><updated>2019-03-15T06:34:28+00:00</updated><id>https://joslefaure.github.io/blog/2019/we-are-all-screwed-yet-no-one-cares-part-ii</id><content type="html" xml:base="https://joslefaure.github.io/blog/2019/we-are-all-screwed-yet-no-one-cares-part-ii/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">We are all screwed: A deep reflexion on life (part I)</title><link href="https://joslefaure.github.io/blog/2019/we-are-all-screwed-a-deep-reflexion-on-life-part-i/" rel="alternate" type="text/html" title="We are all screwed: A deep reflexion on life (part I)"/><published>2019-03-13T06:29:52+00:00</published><updated>2019-03-13T06:29:52+00:00</updated><id>https://joslefaure.github.io/blog/2019/we-are-all-screwed-a-deep-reflexion-on-life-part-i</id><content type="html" xml:base="https://joslefaure.github.io/blog/2019/we-are-all-screwed-a-deep-reflexion-on-life-part-i/"><![CDATA[]]></content><author><name></name></author></entry></feed>